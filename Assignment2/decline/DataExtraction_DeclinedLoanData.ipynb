{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\n",
      ".\\data_rejected\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries we use.\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import datetime\n",
    "import glob\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import zipfile\n",
    "\n",
    "# Save the initial working directory.\n",
    "start_directory = os.getcwd()\n",
    "print(start_directory)\n",
    "\n",
    "# Create the path to the data directory.\n",
    "data_directory = os.path.join('.', 'data_rejected')\n",
    "print(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create logfile.\n",
    "logfile = open(\"time_data.txt\", \"w\") \n",
    "def log_entry(s):\n",
    "    #print('Date now: %s' % datetime.datetime.now())\n",
    "\n",
    "    timestamp = '[%s] ' % datetime.datetime.now()\n",
    "    log_line = timestamp + s + '\\n'\n",
    "    logfile.write(log_line)\n",
    "    logfile.flush()\n",
    "    \n",
    "    # Also write to standard output as a convenience.\n",
    "    print(log_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\ankur\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RejectStatsA.csv.zip|RejectStatsB.csv.zip|RejectStatsD.csv.zip|RejectStats_2016Q1.csv.zip|RejectStats_2016Q2.csv.zip|RejectStats_2016Q3.csv.zip|RejectStats_2016Q4.csv.zip\n",
      "RejectStatsA.csv.zip\n",
      "Downloading file .\\RejectStatsA.csv\n",
      "RejectStatsB.csv.zip\n",
      "Downloading file .\\RejectStatsB.csv\n",
      "RejectStatsD.csv.zip\n",
      "Downloading file .\\RejectStatsD.csv\n",
      "RejectStats_2016Q1.csv.zip\n",
      "Downloading file .\\RejectStats_2016Q1.csv\n",
      "RejectStats_2016Q2.csv.zip\n",
      "Downloading file .\\RejectStats_2016Q2.csv\n",
      "RejectStats_2016Q3.csv.zip\n",
      "Downloading file .\\RejectStats_2016Q3.csv\n",
      "RejectStats_2016Q4.csv.zip\n",
      "Downloading file .\\RejectStats_2016Q4.csv\n"
     ]
    }
   ],
   "source": [
    "base_URL = \"https://resources.lendingclub.com\"\n",
    "url = urllib.request.urlopen(\"https://www.lendingclub.com/info/download-data.action\")\n",
    "content = url.read()\n",
    "#print(content)\n",
    "\n",
    "soup = bsoup(content, 'html')\n",
    "#print(soup) \n",
    "\n",
    "#loanStatsFileNamesJS\n",
    "fileNameDiv = soup.find('div', {\"id\":\"rejectedLoanStatsFileNamesJS\"})\n",
    "loanFileList = fileNameDiv.text.rstrip(\"|\")\n",
    "print(loanFileList)\n",
    "\n",
    "# Set the data directory as the current working directory for the downloads.\n",
    "os.chdir(r'C:/Users/ankur/data')\n",
    "\n",
    "# Download and extract all the data files.\n",
    "for fileName in loanFileList.split(\"|\"):\n",
    "    print(fileName)\n",
    "    \n",
    "    csv_filename = fileName\n",
    "    if csv_filename.endswith('.zip'):\n",
    "        csv_filename = csv_filename[:-4]\n",
    "        \n",
    "    csv_filepath = os.path.join('.', csv_filename)\n",
    "    #print(csv_filepath)\n",
    "    \n",
    "    # Download the file if it isn't already in our data directory.\n",
    "    if os.path.exists(csv_filepath):\n",
    "        print(\"Already downloaded %s\" % csv_filepath)\n",
    "    else:\n",
    "        print(\"Downloading file %s\" % csv_filepath)\n",
    "        file_URL = base_URL + '/' + fileName\n",
    "        #print(file_URL)\n",
    "        \n",
    "        zfile = requests.get(file_URL)\n",
    "        z = zipfile.ZipFile(io.BytesIO(zfile.content))\n",
    "        z.extractall()\n",
    "\n",
    "# Restore the working directory\n",
    "os.chdir(start_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404490, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_filepath = os.path.join(r'C:/Users/Ankur/data_rejected', 'RejectStats_2016Q4.csv')\n",
    "data = pd.read_csv(sample_filepath, skiprows=1)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate(indir=\"./\", outfilename=\"./Rejected_LoanData.csv\"):\n",
    "    initial_working_dir = os.getcwd()\n",
    "    os.chdir(indir)\n",
    "    \n",
    "    csvFileList = glob.glob(\"*.csv\")\n",
    "    dfList = []\n",
    "   \n",
    "    # Process the CSV files, without the initial line.\n",
    "    for csv_filename in csvFileList:\n",
    "        print(csv_filename)\n",
    "        \n",
    "        # Use the file modification time to track when the data was downloaded.\n",
    "        timestamp = int(os.path.getmtime(csv_filename))\n",
    "        #print(\"last modified: %s\" % str(timestamp))\n",
    "        \n",
    "        df = pd.read_csv(csv_filename, low_memory=False, skiprows=1)\n",
    "        \n",
    "        # Add the timestamp into the data.\n",
    "        df['timestamp'] = timestamp\n",
    "        print(df.shape)\n",
    "        \n",
    "        dfList.append(df)\n",
    "        \n",
    "    concatDf = pd.concat(dfList, axis=0, copy=False)\n",
    "    #concatDf.columns = columns\n",
    "    concatDf.to_csv(outfilename, index=None)\n",
    "    print(concatDf.shape)\n",
    "    \n",
    "    # Restore the working directory.\n",
    "    os.chdir(initial_working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RejectStatsA.csv\n",
      "(755491, 10)\n",
      "RejectStatsB.csv\n",
      "(2694642, 10)\n",
      "RejectStatsD.csv\n",
      "(2859379, 10)\n",
      "RejectStats_2016Q1.csv\n",
      "(1096204, 10)\n",
      "RejectStats_2016Q2.csv\n",
      "(996561, 10)\n",
      "RejectStats_2016Q3.csv\n",
      "(1272619, 10)\n",
      "RejectStats_2016Q4.csv\n",
      "(1404490, 10)\n",
      "(11079386, 10)\n"
     ]
    }
   ],
   "source": [
    "concatenate(indir=r'C:/Users/Ankur/data_rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
