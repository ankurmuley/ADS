{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.api import ClassifierI, MultiClassifierI\n",
    "from nltk.classify.megam import config_megam, call_megam\n",
    "from nltk.classify.weka import WekaClassifier, config_weka\n",
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "from nltk.classify.positivenaivebayes import PositiveNaiveBayesClassifier\n",
    "from nltk.classify.decisiontree import DecisionTreeClassifier\n",
    "from nltk.classify.rte_classify import rte_classifier, rte_features, RTEFeatureExtractor\n",
    "from nltk.classify.util import accuracy, apply_features, log_likelihood\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify.maxent import (MaxentClassifier, BinaryMaxentFeatureEncoding,\n",
    "                                  TypedMaxentFeatureEncoding,\n",
    "                                  ConditionalExponentialClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK Name corpus to train a Gender Identification classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names: 7944\n",
      "[('Hewitt', 'male'), ('Ewart', 'male'), ('Carita', 'female'), ('Rockwell', 'male'), ('Sanderson', 'male'), ('Marris', 'female'), ('Horst', 'male'), ('Ioana', 'female'), ('Zulema', 'female'), ('Ambrose', 'male')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)\n",
    "print('Total names:',len(names))\n",
    "print(names[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'y'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The most important thing for a text classifier is feature, which can be very flexible, and defined by human engineer. Here, we just use the final letter of a given name as the feature, and build a dictionary containing relevant information about a given name:\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Gary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature sets is 7944\n",
      "[({'last_letter': 't'}, 'male'), ({'last_letter': 't'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'l'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 's'}, 'female'), ({'last_letter': 't'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'e'}, 'male')]\n",
      "Length of training set is 7444\n",
      "Length of testing set is  500\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), g) for (n, g) in names]\n",
    "print('Length of feature sets is',len(featuresets))\n",
    "print(featuresets[0:10])\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "print('Length of training set is',len(train_set))\n",
    "print('Length of testing set is ',len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training a Naive Bayes classifier for Gender Identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Naive Bayes Classifier is 0.744\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     38.0 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.6 : 1.0\n",
      "             last_letter = 'p'              male : female =     21.2 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.1 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#A learning algorithm is very useful for a classifier, here we will show you how to use the Naive Bayes.\n",
    "from nltk import NaiveBayesClassifier\n",
    "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
    "nb_classifier.classify(gender_features('Gary'))\n",
    "nb_classifier.classify(gender_features('Grace'))\n",
    "from nltk import classify\n",
    "print('Accuracy using Naive Bayes Classifier is',classify.accuracy(nb_classifier, test_set))\n",
    "nb_classifier.show_most_informative_features(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Using Gutenberg and Web_text data. Finding what are the top 5 words that Shakespeare used but we do not use in currently. -Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Top 50 words from Shakespeare :\n",
      " [('haue', 448), ('ham', 337), ('thou', 312), ('shall', 300), ('lord', 293), ('come', 232), ('king', 231), ('enter', 230), ('good', 218), ('let', 217), ('thy', 202), ('caesar', 193), ('vs', 184), ('know', 176), ('thee', 174), ('would', 170), ('vpon', 162), ('brutus', 162), ('like', 162), ('bru', 153), ('well', 152), ('hath', 144), ('selfe', 143), ('man', 139), ('may', 138), ('macb', 137), ('yet', 136), ('heere', 135), ('must', 130), ('say', 130), ('tis', 129), ('th', 125), ('make', 119), ('speake', 119), ('loue', 119), ('giue', 118), ('see', 116), ('time', 115), ('sir', 114), ('night', 114), ('one', 112), ('st', 110), ('cassi', 107), ('ile', 106), ('doe', 103), ('hamlet', 100), ('go', 100), ('men', 96), ('hor', 95), ('vp', 94)]\n"
     ]
    }
   ],
   "source": [
    "File = []\n",
    "File.extend(gutenberg.words('shakespeare-caesar.txt'))\n",
    "File.extend(gutenberg.words('shakespeare-hamlet.txt'))\n",
    "File.extend(gutenberg.words('shakespeare-macbeth.txt'))\n",
    "from collections import Counter\n",
    "shakespeare = [F.lower() for F in File]\n",
    "from nltk.corpus import stopwords\n",
    "filter_file = [word for word in shakespeare if word not in stopwords.words('english')]\n",
    "sh = []\n",
    "for h in filter_file:\n",
    "    if h.isalpha():\n",
    "        sh.append(h)\n",
    "#print(sh)\n",
    "from collections import Counter\n",
    "shakespeare = Counter(sh)\n",
    "top_50_shakespeare = shakespeare.most_common(50)\n",
    "print(\" Top 50 words from Shakespeare :\\n\",top_50_shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
