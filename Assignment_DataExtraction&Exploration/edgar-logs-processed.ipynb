{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the libraries we use.\n",
    "import datetime\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Create logfile.\n",
    "logfile = open(\"edgar-logs-logfile.txt\", \"w\")\n",
    "def log_entry(s):\n",
    "    #print('Date now: %s' % datetime.datetime.now())\n",
    "\n",
    "    timestamp = '[%s] ' % datetime.datetime.now()\n",
    "    log_line = timestamp + s + '\\n'\n",
    "    logfile.write(log_line)\n",
    "    logfile.flush()\n",
    "    \n",
    "    # Also write to standard output as a convenience.\n",
    "    print(log_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# User provided inputs.\n",
    "year = \"2003\"\n",
    "\n",
    "# Useful constants.\n",
    "site = \"https://www.sec.gov/data/edgar-log-file-data-set.html\"\n",
    "print(site)\n",
    "\n",
    "link = \"https://www.sec.gov/files/edgar{year}.html\".format(year=year)\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(site)\n",
    "print(response.status_code)\n",
    "\n",
    "# TODO: error handling when the page can't be retrieved.\n",
    "\n",
    "content = response.content\n",
    "print(content[0:200])\n",
    "\n",
    "# Check whether the given year appears on the EDGAR log page and exit if it doesn't.\n",
    "check_text = \"files/edgar{year}.html\".format(year=year)\n",
    "if str(content).find(check_text) != -1:\n",
    "    log_entry(\"Year \" + str(year) + \" is valid\")\n",
    "else:\n",
    "    log_entry(\"Year \" + str(year) + \" is not valid\")\n",
    "    # TODO - throw an error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the year  2008\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080101.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080201.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080301.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080401.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080501.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080601.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080701.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080801.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080901.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081001.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081101.zip\n",
      "http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081201.zip\n",
      "[{'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080101.zip', 'filename': 'log20080101.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080201.zip', 'filename': 'log20080201.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr1/log20080301.zip', 'filename': 'log20080301.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080401.zip', 'filename': 'log20080401.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080501.zip', 'filename': 'log20080501.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr2/log20080601.zip', 'filename': 'log20080601.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080701.zip', 'filename': 'log20080701.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080801.zip', 'filename': 'log20080801.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr3/log20080901.zip', 'filename': 'log20080901.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081001.zip', 'filename': 'log20081001.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081101.zip', 'filename': 'log20081101.zip'}, {'url': 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2008/Qtr4/log20081201.zip', 'filename': 'log20081201.zip'}]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'log2008\"+str(num).zfill(2)+\"01.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-652ca7747af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log{year}\"+str(num).zfill(2)+\"01.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[1;31m#f = open(\"log2003\"+str(num).zfill(2)+\"01.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cik'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'log2008\"+str(num).zfill(2)+\"01.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Months in the year and the quarter to which a month belongs are constants.\n",
    "import zipfile, io\n",
    "year=input(\"Enter the year  \")\n",
    "months_dict = [{\"month\":\"01\", \"quarter\":1}, {\"month\":\"02\", \"quarter\":1}, {\"month\":\"03\", \"quarter\":1},\n",
    "              {\"month\":\"04\", \"quarter\":2}, {\"month\":\"05\", \"quarter\":2}, {\"month\":\"06\", \"quarter\":2},\n",
    "              {\"month\":\"07\", \"quarter\":3}, {\"month\":\"08\", \"quarter\":3}, {\"month\":\"09\", \"quarter\":3},\n",
    "              {\"month\":\"10\", \"quarter\":4}, {\"month\":\"11\", \"quarter\":4}, {\"month\":\"12\", \"quarter\":4}]\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for m in months_dict:\n",
    "        url = \"http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/{year}/Qtr{quarter}/log{year}{month}01.zip\".format(year=year, month=m['month'], quarter = str(m['quarter']))\n",
    "        filenames.append({'url':url,'filename':\"log\" + str(year) + m['month'] + \"01.zip\"})\n",
    "        print(url) \n",
    "        zfile = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(zfile.content))\n",
    "        z.extractall()  \n",
    "           \n",
    "#print(filenames)\n",
    "\n",
    "for num in range(2,13):\n",
    "    data=pd.read_csv(\"log{year}\"+str(num).zfill(2)+\"01.csv\".format(year=year)) \n",
    "    #f = open(\"log2003\"+str(num).zfill(2)+\"01.csv\")\n",
    "    data['size'] = data['size'].fillna(data.groupby(['cik'])['size'].transform('mean'))\n",
    "    #example dataset of normally distributed data.\n",
    "    df=pd.data({'data':np.random.normal(size=200)})   \n",
    "    clean_col=df[np.abs(df.data-df.data.mean())<=(3*df.data.std())]\n",
    "    print(clean_col)\n",
    "#print(data) \n",
    "    new_csv=data.to_csv('log{year}\"+str(num).zfill(2)+\"01.csv', sep=',', encoding='utf-8')\n",
    "    print(new_csv)\n",
    "\n",
    "#df = pd.DataFrame.from_csv(log20030101.zip.namelist())\n",
    "#print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ip        date      time   zone        cik  \\\n",
      "0          24.70.95.bjg  2004-01-01  00:00:00  500.0   771252.0   \n",
      "1        64.165.202.fca  2004-01-01  00:00:00  500.0   849778.0   \n",
      "2       207.168.174.jdd  2004-01-01  00:00:01  500.0  1244190.0   \n",
      "3        64.165.202.fca  2004-01-01  00:00:02  500.0   849778.0   \n",
      "4        64.165.202.fca  2004-01-01  00:00:03  500.0   849778.0   \n",
      "5        64.165.202.fca  2004-01-01  00:00:03  500.0  1233345.0   \n",
      "6       207.168.174.jdd  2004-01-01  00:00:04  500.0  1244131.0   \n",
      "7        64.165.202.fca  2004-01-01  00:00:04  500.0  1233345.0   \n",
      "8        68.100.240.hbh  2004-01-01  00:00:04  500.0  1006837.0   \n",
      "9        64.165.202.fca  2004-01-01  00:00:05  500.0   849778.0   \n",
      "10       64.165.202.fca  2004-01-01  00:00:06  500.0   849778.0   \n",
      "11       64.165.202.fca  2004-01-01  00:00:06  500.0  1033012.0   \n",
      "12       64.165.202.fca  2004-01-01  00:00:08  500.0  1233345.0   \n",
      "13       64.165.202.fca  2004-01-01  00:00:08  500.0   849778.0   \n",
      "14          68.5.10.bif  2004-01-01  00:00:08  500.0   225852.0   \n",
      "15          68.5.10.bif  2004-01-01  00:00:08  500.0   225852.0   \n",
      "16       64.165.202.fca  2004-01-01  00:00:09  500.0  1033012.0   \n",
      "17      128.122.129.ech  2004-01-01  00:00:11  500.0  1164727.0   \n",
      "18      207.168.174.jdd  2004-01-01  00:00:13  500.0  1243670.0   \n",
      "19       64.165.202.fca  2004-01-01  00:00:14  500.0  1160294.0   \n",
      "20      207.168.174.jdd  2004-01-01  00:00:17  500.0  1243302.0   \n",
      "21         68.221.9.fcg  2004-01-01  00:00:17  500.0   890908.0   \n",
      "22      207.168.174.jdd  2004-01-01  00:00:19  500.0  1243236.0   \n",
      "23       64.165.202.fca  2004-01-01  00:00:20  500.0     9235.0   \n",
      "24       64.165.202.fca  2004-01-01  00:00:21  500.0  1160294.0   \n",
      "25          68.5.10.bif  2004-01-01  00:00:21  500.0   225852.0   \n",
      "26       64.165.202.fca  2004-01-01  00:00:23  500.0     9235.0   \n",
      "27      207.168.174.jdd  2004-01-01  00:00:24  500.0  1243108.0   \n",
      "28      152.163.252.ahb  2004-01-01  00:00:25  500.0  1047699.0   \n",
      "29       64.165.202.fca  2004-01-01  00:00:25  500.0     9235.0   \n",
      "...                 ...         ...       ...    ...        ...   \n",
      "440148    24.128.96.beh  2004-01-01  23:59:54  500.0  1012482.0   \n",
      "440149    67.163.95.ced  2004-01-01  23:59:54  500.0  1085158.0   \n",
      "440150  205.188.208.fca  2004-01-01  23:59:55  500.0  1269155.0   \n",
      "440151  207.168.174.jdd  2004-01-01  23:59:55  500.0    62741.0   \n",
      "440152  207.168.174.jdd  2004-01-01  23:59:55  500.0    62741.0   \n",
      "440153    24.128.96.beh  2004-01-01  23:59:55  500.0  1012482.0   \n",
      "440154    24.128.96.beh  2004-01-01  23:59:55  500.0  1012482.0   \n",
      "440155    24.128.96.beh  2004-01-01  23:59:55  500.0  1012482.0   \n",
      "440156    24.128.96.beh  2004-01-01  23:59:55  500.0  1098345.0   \n",
      "440157   202.71.146.jdd  2004-01-01  23:59:56  500.0    19612.0   \n",
      "440158  205.188.209.gfa  2004-01-01  23:59:56  500.0  1225715.0   \n",
      "440159    24.128.96.beh  2004-01-01  23:59:56  500.0  1098345.0   \n",
      "440160    24.128.96.beh  2004-01-01  23:59:56  500.0  1098345.0   \n",
      "440161    24.128.96.beh  2004-01-01  23:59:56  500.0  1012482.0   \n",
      "440162    24.128.96.beh  2004-01-01  23:59:56  500.0  1098345.0   \n",
      "440163    24.128.96.beh  2004-01-01  23:59:56  500.0  1098345.0   \n",
      "440164    24.128.96.beh  2004-01-01  23:59:56  500.0  1098345.0   \n",
      "440165    24.128.96.beh  2004-01-01  23:59:57  500.0  1098345.0   \n",
      "440166    24.128.96.beh  2004-01-01  23:59:57  500.0  1098345.0   \n",
      "440167    65.171.24.gjc  2004-01-01  23:59:57  500.0  1105841.0   \n",
      "440168    24.128.96.beh  2004-01-01  23:59:58  500.0  1098345.0   \n",
      "440169    24.128.96.beh  2004-01-01  23:59:58  500.0  1098345.0   \n",
      "440170    24.128.96.beh  2004-01-01  23:59:58  500.0  1098345.0   \n",
      "440171    24.128.96.beh  2004-01-01  23:59:58  500.0  1098345.0   \n",
      "440172    24.128.96.beh  2004-01-01  23:59:58  500.0  1098345.0   \n",
      "440173    24.128.96.beh  2004-01-01  23:59:59  500.0  1098345.0   \n",
      "440174    24.128.96.beh  2004-01-01  23:59:59  500.0  1098345.0   \n",
      "440175    24.128.96.beh  2004-01-01  23:59:59  500.0  1098345.0   \n",
      "440176    24.128.96.beh  2004-01-01  23:59:59  500.0  1098345.0   \n",
      "440177    24.61.133.ajc  2004-01-01  23:59:59  500.0  1086933.0   \n",
      "\n",
      "                   accession                    extention   code  \\\n",
      "0       0001047469-03-042434             a2125426zs-3.htm  200.0   \n",
      "1       0000927016-03-001282                  dex1014.txt  200.0   \n",
      "2       0001244190-03-000001                    edgar.xml  200.0   \n",
      "3       0000927016-03-001282                  dex1015.txt  200.0   \n",
      "4       0000927016-03-001282                   dex211.htm  200.0   \n",
      "5       0001104659-03-028220                   -index.htm  200.0   \n",
      "6       0001233402-03-000173                    edgar.xml  200.0   \n",
      "7       0001104659-03-028220             a03-6155_18k.htm  200.0   \n",
      "8       0001036050-98-001190                         .txt  200.0   \n",
      "9       0000927016-03-001282                   dex231.htm  200.0   \n",
      "10      0000927016-03-001282                   dex991.htm  200.0   \n",
      "11      0000950124-03-001053                   -index.htm  200.0   \n",
      "12      0001104659-03-028220           a03-6155_1ex20.htm  200.0   \n",
      "13      0000927016-03-001282                   dex992.htm  200.0   \n",
      "14      0000950115-98-000678                         .txt  200.0   \n",
      "15      0000950115-98-000678                         .txt  200.0   \n",
      "16      0000950124-03-001053             k74930def14a.htm  200.0   \n",
      "17      0001045969-03-000796                   -index.htm  200.0   \n",
      "18      0000914317-03-003777         form4-56179_psex.xml  200.0   \n",
      "19      0001047469-03-009734                   -index.htm  200.0   \n",
      "20      0000006284-03-000302                 edgardoc.xml  200.0   \n",
      "21      0001193125-03-099088                   dex992.htm  200.0   \n",
      "22      0001024780-03-000004              primary_doc.xml  200.0   \n",
      "23      0000950123-03-003707                   -index.htm  200.0   \n",
      "24      0001047469-03-009734            a2105646z10-k.htm  200.0   \n",
      "25      0000950115-99-000462                         .txt  200.0   \n",
      "26      0000950123-03-003707              y84763e10vk.txt  200.0   \n",
      "27      0000086115-03-000020                 edgardoc.xml  200.0   \n",
      "28      0000950144-03-005010            g81999exv99w2.txt  200.0   \n",
      "29      0000950123-03-003707            y84763exv23w1.txt  200.0   \n",
      "...                      ...                          ...    ...   \n",
      "440148  0001259105-03-000001                   -index.htm  200.0   \n",
      "440149  0001085158-03-000007                         .txt  200.0   \n",
      "440150  0001094328-03-000311    ibizinc10sb110503woex.txt  200.0   \n",
      "440151  0000062741-03-000293  c0001093039d20031125f4f.xml  200.0   \n",
      "440152  0000062741-03-000293                   -index.htm  200.0   \n",
      "440153  0001259105-03-000004                         .txt  200.0   \n",
      "440154  0001259105-03-000002                   -index.htm  200.0   \n",
      "440155  0001259105-03-000003                         .txt  200.0   \n",
      "440156  0001104540-00-000272                   -index.htm  200.0   \n",
      "440157  0000905729-01-500068               proxywhole.htm  304.0   \n",
      "440158  0001179110-03-013634         xslF345X02/edgar.xml  200.0   \n",
      "440159  0001104540-00-000277                   -index.htm  200.0   \n",
      "440160  0001104540-00-000272                         .txt  200.0   \n",
      "440161  9999999997-02-027916                   -index.htm  200.0   \n",
      "440162  0001104540-00-000291                         .txt  200.0   \n",
      "440163  0001104540-00-000277                         .txt  200.0   \n",
      "440164  0001104540-00-000179                         .txt  200.0   \n",
      "440165  0001104540-01-500030                         .txt  200.0   \n",
      "440166  0001104540-00-000342                   -index.htm  200.0   \n",
      "440167  0001188112-03-000828                t10q-1092.txt  200.0   \n",
      "440168  0001104540-00-000291                   -index.htm  200.0   \n",
      "440169  0001104540-01-500033                   -index.htm  200.0   \n",
      "440170  0001104540-01-500030                   -index.htm  200.0   \n",
      "440171  0001104540-01-500029                         .txt  200.0   \n",
      "440172  0001104540-00-000342                         .txt  200.0   \n",
      "440173  0001104540-01-500148                   -index.htm  200.0   \n",
      "440174  0001104540-01-500104                         .txt  200.0   \n",
      "440175  0001104540-01-500029                   -index.htm  200.0   \n",
      "440176  0001104540-01-500033                         .txt  200.0   \n",
      "440177  0000899681-00-000423                   -index.htm  304.0   \n",
      "\n",
      "                size  idx  norefer  noagent  find  crawler browser  \n",
      "0       1.235580e+05  0.0      0.0      0.0  10.0      0.0     win  \n",
      "1       3.868800e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "2       5.683000e+03  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "3       1.703800e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "4       9.025000e+03  0.0      1.0      0.0   0.0      0.0     win  \n",
      "5       2.144000e+03  1.0      1.0      0.0   0.0      0.0     win  \n",
      "6       2.740000e+03  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "7       2.694800e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "8       8.381580e+05  0.0      0.0      0.0   1.0      0.0     win  \n",
      "9       2.496000e+03  0.0      1.0      0.0   0.0      0.0     win  \n",
      "10      4.004000e+03  0.0      1.0      0.0   0.0      0.0     win  \n",
      "11      3.068000e+03  1.0      1.0      0.0   0.0      0.0     win  \n",
      "12      3.374410e+05  0.0      1.0      0.0   0.0      0.0     win  \n",
      "13      4.019000e+03  0.0      1.0      0.0   0.0      0.0     win  \n",
      "14      6.243900e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "15      6.680200e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "16      1.863740e+05  0.0      1.0      0.0   0.0      0.0     win  \n",
      "17      4.628000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "18      1.119800e+04  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "19      6.091000e+03  1.0      1.0      0.0   0.0      0.0     win  \n",
      "20      2.881000e+03  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "21      2.882000e+03  0.0      0.0      0.0   9.0      0.0     win  \n",
      "22      4.166100e+04  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "23      3.304000e+03  1.0      1.0      0.0   0.0      0.0     win  \n",
      "24      4.957170e+05  0.0      1.0      0.0   0.0      0.0     win  \n",
      "25      6.175500e+04  0.0      1.0      0.0   0.0      0.0     win  \n",
      "26      1.982480e+05  0.0      1.0      0.0   0.0      0.0     win  \n",
      "27      3.556000e+03  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "28      5.199000e+03  0.0      0.0      0.0   7.0      0.0     mie  \n",
      "29      1.005000e+03  0.0      1.0      0.0   0.0      0.0     win  \n",
      "...              ...  ...      ...      ...   ...      ...     ...  \n",
      "440148  2.935000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440149  1.191421e+06  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440150  1.221440e+05  0.0      1.0      0.0   0.0      0.0     mie  \n",
      "440151  5.372000e+03  0.0      1.0      1.0   0.0      0.0     NaN  \n",
      "440152  3.158000e+03  1.0      1.0      1.0   0.0      0.0     NaN  \n",
      "440153  8.952000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440154  2.935000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440155  1.493800e+04  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440156  3.663000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440157  6.871915e+04  0.0      0.0      0.0   9.0      0.0     win  \n",
      "440158  1.541700e+04  0.0      0.0      0.0   9.0      0.0     win  \n",
      "440159  3.789000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440160  9.823000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440161  2.233000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440162  9.993000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440163  9.877000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440164  1.476820e+05  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440165  9.453000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440166  2.335000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440167  1.330270e+05  0.0      0.0      0.0   9.0      0.0     win  \n",
      "440168  4.023000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440169  3.135000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440170  3.106000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440171  9.401000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440172  2.365400e+04  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440173  2.101000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440174  8.777800e+04  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440175  3.009000e+03  1.0      0.0      0.0   1.0      0.0     win  \n",
      "440176  9.404000e+03  0.0      0.0      0.0   1.0      0.0     win  \n",
      "440177  9.223144e+04  1.0      0.0      0.0   1.0      0.0     mie  \n",
      "\n",
      "[440178 rows x 15 columns]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'log20040101.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e22f7261b4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log20040101.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1458\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1459\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1461\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mahesh\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression, memory_map)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'log20040101.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#pd.read_csv(\"C:\\Users\\mahesh\\Desktop\\Data science\\Data_Science\")\n",
    "#df_data = pd.read_csv('log20030101', sep=',\\s+', header=None, skiprows=3)[range(7)].set_index(0)\n",
    "\n",
    "import csv\n",
    "#with open('log20030101.csv') as csvfile:\n",
    "    #reader = csv.DictReader(csvfile)\n",
    "    #for row in reader:\n",
    "            #print(row['first_name'], row['last_name'])\n",
    "        \n",
    "        \n",
    "#ifile = open('C:\\\\Users\\\\mahesh\\\\Desktop\\\\Data science\\\\Data_Science\\\\log20030101.csv', \"rb\")\n",
    "\n",
    "#import csv\n",
    "#with open(ifile) as f:\n",
    "    #f = dropwhile(lambda x: x.startswith(\"#!!\"), f)\n",
    "    #r = csv.reader(f)\n",
    "    #df = pd.DataFrame().from_records(r)\n",
    "import pandas as pd\n",
    "\n",
    "for m in months_dict:\n",
    "\n",
    "url = log{year}{month}01.zip.format(year=year, month=m['month'], quarter = str(m['quarter']))\n",
    "filenames.append({'url':url,'filename':\"log\" + str(year) + m['month'] + \"01.zip\"})\n",
    "        print(url) \n",
    "        zfile = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(zfile.content))\n",
    "        z.extractall()\n",
    "data=pd.read_csv('log20030101.csv') \n",
    "#print(data)\n",
    "#data.groupby('size')\n",
    "#d1=df1.groupby( [ \"size\", \"accession\"] )\n",
    "#print(d1)\n",
    "\n",
    "#df = data.groupby(data.columns, axis = 1).transform(lambda x: x.fillnan(x.mean()))\n",
    "#print(df)\n",
    "\n",
    "\n",
    "#data['size'] = sub2['income'].fillna((sub2['income'].mean()))\n",
    "#data['size'] = data['size'].fillna(data.groupby(['cik','ip'])['size'].transform('mean'))\n",
    "data['size'] = data['size'].fillna(data.groupby(['cik'])['size'].transform('mean'))\n",
    "print(data) \n",
    "\n",
    "data.to_csv('log20040101.csv', sep=',', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "comb2003 = open(\"log2003_latest.csv\", \"a\")\n",
    "#testing 1 file\n",
    "for line in open (\"log20030101.csv\"):\n",
    "    comb2003.write(line)\n",
    "    \n",
    "#combining all files of a particular year\n",
    "for num in range(2,13):\n",
    "    f = open(\"log2003\"+str(num).zfill(2)+\"01.csv\")\n",
    "    print(str(num).zfill(2))\n",
    "    next(f) #to skip the header\n",
    "    for line in f:\n",
    "        comb2003.write(line)\n",
    "    f.close()\n",
    "comb2003.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = ['ip','date','time','zone','cik','accession','doc','code','filesize','idx',\n",
    "         'norefer','noagent','find','crawler','browser']\n",
    "\n",
    "column_types = {'ip':np.object, 'date':np.object, 'time':np.object, 'zone':np.object,\n",
    "                'cik':np.object, 'accession':np.object, 'doc':np.object, 'code':np.object,\n",
    "                'filesize':np.object, 'idx':np.object, 'norefer':np.int32, 'noagent':np.int32, \n",
    "                'find':np.object, 'crawler':np.object, 'browser':np.object}\n",
    "\n",
    "# CIK, filesize, code, idx, find and crawler should be ints, but they have missing values.\n",
    "\n",
    "def process_monthly_file(item):\n",
    "    url = item['url']\n",
    "    zip_filename = item['filename']\n",
    "    csv_filename = zip_filename.replace('zip', 'csv')\n",
    "\n",
    "    log_entry('Processing: ' + zip_filename)\n",
    "    \n",
    "    # Download and save the ZIP file (if we haven't already).\n",
    "    if not os.path.isfile(csv_filename):\n",
    "        log_entry('Downloading: ' + zip_filename)\n",
    "        r = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall()\n",
    "    else:\n",
    "        log_entry('Already downloaded: ' + csv_filename)\n",
    "    \n",
    "    # Read the data into a dataframe and return it.\n",
    "    tp = pd.read_csv(csv_filename, header=0, names=column_names, dtype=column_types, iterator=True, chunksize=1000)  # gives TextFileReader, which is iterable with chunks of 1000 rows.\n",
    "    df = pd.concat(tp, ignore_index=True)  # df is DataFrame. If errors, do `list(tp)` instead of `tp`\n",
    "    #df = pd.read_csv(csv_filename, header=0, names=column_names, dtype=column_types)\n",
    "\n",
    "    convert_columns = ['cik', 'code', 'filesize', 'idx', 'find', 'crawler']\n",
    "    for c in convert_columns:\n",
    "        log_entry('Replacing missing ' + c + ' values with 0 and converting to integer')\n",
    "        df[c].fillna(0.0, inplace=True)\n",
    "        df[c] = df[c].astype(float)\n",
    "        df[c] = df[c].astype(int)\n",
    "\n",
    "    # Missing values in browser are set to ''.\n",
    "    log_entry('Replacing missing browsers with empty string')\n",
    "    df['browser'].fillna('', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test process_monthly_file() with a single file.\n",
    "item = {'url':'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2003/Qtr1/log20030101.zip', \n",
    "        'filename':'log20030101.zip'}\n",
    "df = process_monthly_file(item)\n",
    "print(df.head(5))\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_entry(\"Summary stats for filesize: \" + df['date'][0])\n",
    "print(df['filesize'].describe(include=[np.number]))\n",
    "\n",
    "log_entry(\"Summary stats for categoricals: IP, time, accession, doc, browser: \" + df['date'][0])\n",
    "print(df[['ip', 'time', 'accession', 'doc', 'browser']].describe(include=[object]))\n",
    "\n",
    "log_entry(\"Value counts for browser: \" + df['date'][0])\n",
    "print(df['browser'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item = {'url':'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2003/Qtr1/log20030101.zip', \n",
    "        'filename':'log20030101.zip'}\n",
    "df = process_monthly_file(item)\n",
    "dataframes = []\n",
    "for f in filename[0:1]:\n",
    "    monthly_df = process_monthly_file(f)\n",
    "    dataframes.append(monthly_df)\n",
    "    \n",
    "import zipfile, io\n",
    "zfile = requests.get(\"http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/2003/Qtr1/log20030101.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(zfile.content))\n",
    "z.extractall() \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/example.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to hold the summary data.\n",
    "#summary_df = pd.DataFrame()\n",
    "for df in dataframes:\n",
    "    #compute_summary_metrics(df, summary_df)\n",
    "    log_entry('computing summary metrics for ' + df['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
